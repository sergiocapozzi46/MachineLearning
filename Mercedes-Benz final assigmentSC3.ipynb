{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "Reduce the time a Mercedes-Benz spends on the test bench.\n",
    "\n",
    "Problem Statement Scenario:\n",
    "Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include the passenger safety cell with a crumple zone, the airbag, and intelligent assistance systems. Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium carmakers. Mercedes-Benz is the leader in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams.\n",
    "\n",
    "To ensure the safety and reliability of every unique car configuration before they hit the road, the company’s engineers have developed a robust testing system. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on Mercedes-Benz’s production lines. However, optimizing the speed of their testing system for many possible feature combinations is complex and time-consuming without a powerful algorithmic approach.\n",
    "\n",
    "You are required to reduce the time that cars spend on the test bench. Others will work with a dataset representing different permutations of features in a Mercedes-Benz car to predict the time it takes to pass testing. Optimal algorithms will contribute to faster testing, resulting in lower carbon dioxide emissions without reducing Mercedes-Benz’s standards.\n",
    "\n",
    "Following actions should be performed:\n",
    "\n",
    "1. If for any column(s), the variance is equal to zero, then you need to remove those variable(s).\n",
    "2. Check for null and unique values for test and train sets.\n",
    "3. Apply label encoder.\n",
    "4. Perform dimensionality reduction.\n",
    "5. Predict your test_df values using XGBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Reading and studying the dataset\n",
    "We read the train dataset and study it to decide the needed steps to carry out the three initial tasks from the list mentioned above.\n",
    "1. If for any column(s), the variance is equal to zero, then you need to remove those variable(s).\n",
    "2. Check for null and unique values for test and train sets.\n",
    "3. Apply label encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all variables and import Numpy and Pandas libraries\n",
    "%reset -f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Upload/read both TRAIN and TEST data with pandas\n",
    "DFTRAIN = pd.read_csv('train.csv')\n",
    "DFTEST= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the TRAIN dataframe\n",
      "There are no missing values in the TEST dataframe\n"
     ]
    }
   ],
   "source": [
    "# Checking for Missing values in TEST and TRAIN dataframes (Item 2 above)\n",
    "def check_missing_values(df, name):\n",
    "    if df.isnull().any().any():\n",
    "        print(\"There are missing values in the dataframe\", name, \"dataframe\")\n",
    "    else:\n",
    "        print(\"There are no missing values in the\", name, \"dataframe\")\n",
    "check_missing_values(DFTRAIN, \"TRAIN\")\n",
    "check_missing_values(DFTEST, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4209 entries, 0 to 4208\n",
      "Columns: 378 entries, ID to X385\n",
      "dtypes: float64(1), int64(369), object(8)\n",
      "memory usage: 12.1+ MB\n",
      "\n",
      "TEST SET\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4209 entries, 0 to 4208\n",
      "Columns: 377 entries, ID to X385\n",
      "dtypes: int64(369), object(8)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#using \"info\" to learn more about the train and test data\n",
    "print(\"TRAIN SET\")\n",
    "DFTRAIN.info()\n",
    "print(\"\\nTEST SET\")\n",
    "DFTEST.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the frame:  (4209, 378)\n",
      "We have thus 4209 samples, 1 target and 376 features (ID column is not used)\n",
      "All features are labeled as 'X...'. The target is labeled as 'y'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the result above we see that we have 4209 rows and 378 columns\n",
    "# Let us see the data and headers to understand the frame\n",
    "print(\"The shape of the frame: \", DFTRAIN.shape)\n",
    "print(\"We have thus 4209 samples, 1 target and 376 features (ID column is not used)\")\n",
    "print(\"All features are labeled as 'X...'. The target is labeled as 'y'\")\n",
    "DFTRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items that have clones 298\n",
      "Number of features: 376\n",
      "Number of Feature types:\n",
      "int64     368\n",
      "object      8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many samples have exactly the same feature set. \n",
    "# We know from figure above that the columns that contain the features are 2:377\n",
    "# The duplicated number of samples that have the same feature set is thus 298\n",
    "b = DFTRAIN[DFTRAIN.duplicated(subset=DFTRAIN.columns[2:], keep='first')]\n",
    "print(\"Number of items that have clones\", b.shape[0])\n",
    "# Now look at the kind of data in features\n",
    "cols = [c for c in DFTRAIN.columns if 'X' in c]\n",
    "print(f\"Number of features: {len(cols)}\")\n",
    "print('Number of Feature types:')\n",
    "print(DFTRAIN[cols].dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Transforming the dataset to suit better the model achievement\n",
    "We remove now from the train dataset the features (colums) that contain a unique value. (item 1 from above)\n",
    "\n",
    "Two identical samples (rows) may have different target measurements. We will do the following steps to remove samples with repeated input:\n",
    "1. Take the mean value of the target \"y\" for all samples (rows) with identical input.\n",
    "2. Eliminate all but one the samples (rows) having the same feature input.\n",
    "3. Replace the target value \"y\" of remained clone with the mean value from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of removed features is 12\n",
      "Mean value of std for clones: 4.13 in 217 rows\n"
     ]
    }
   ],
   "source": [
    "# A) Remove colums that contain a unique value for all samples from a copy of the train set.\n",
    "import time  # MUCH FASTER THAN ALTERNATIVE WAYS\n",
    "X_DF = DFTRAIN.copy()\n",
    "import math as math\n",
    "colsRmv = [] # Used later to remove the same columns from the test dataframe\n",
    "for c in cols:\n",
    "    if len(np.unique(X_DF[c])) == 1: # True if all values in columns are 1\n",
    "        del X_DF[c] # X_DF.drop(c, axis=\"columns\", inplace=True) # actually edit the dataframe\n",
    "        colsRmv.append(c)      \n",
    "print(\"Number of removed features is\", DFTRAIN.shape[1]-X_DF.shape[1])\n",
    "# From the reduced feature set we remove samples having the identical features.\n",
    "# By doing that we increase the accuracy of the predictions\n",
    "b = X_DF[X_DF.duplicated(subset=X_DF.columns[2:], keep=False)].copy() # b is an auxiliary dataframe with all clones\n",
    "X_DF = X_DF.drop_duplicates(subset=X_DF.columns[2:], keep='first').copy() # copy() doesn't keep index\n",
    "b.reset_index(drop=True, inplace=True) # Otherwise index may be larger than b.shape[0]\n",
    "b1 = [] # A list condensing all the feature values of a sample in \"b\" to one string object\n",
    "for i in range(b.shape[0]):\n",
    "    a2 = b.iloc[i, 2:].tolist() # From series to list\n",
    "    a1 = a2[0] # It is a character, e.g. \"k\"\n",
    "    for j in range(1,len(a2)):\n",
    "        if j < 8:\n",
    "            a1 += a2[j] # e.g. v, at, a, d, u, j, o\n",
    "        else:\n",
    "            a1 += chr(65 +a2[j]) # \"A\" if a2[j]= 0 or \"B\" if 1\n",
    "    b1.append(a1) # b1 = [[\"kv ....B\"], [ ...]]\n",
    "# Modify Dataframe \"b\" to contain just the single condensed feature in order to make it easy to take y mean\n",
    "b.insert(2, \"NEW\", b1) # Dataframe b has a new column 2 named \"NEW\". Old columns 2:end are right displaced.\n",
    "b.drop(b.columns[3:], axis=\"columns\", inplace=True) # Frame b is much simpler now\n",
    "\n",
    "# ALTERNATIVA 1 - Does not change dataframe b\n",
    "t = time.perf_counter()\n",
    "std = []\n",
    "d = []\n",
    "for i in range(len(b1)):\n",
    "    if  not(b1[i] == \"0\"):\n",
    "        a1 = b1[i] #  The first element of a series of clones\n",
    "        while True:\n",
    "            try:\n",
    "                d.append(b1.index(a1)) # find the first remaining index in b1 containing a1\n",
    "                b1[d[-1]] = \"0\" # this (last) item in b1 will not be found again     \n",
    "            except ValueError:\n",
    "                break # Takes place when b1.index(a1) is exausted\n",
    "        a1 = b.iloc[d, 1].values.mean() # Average values of identical items in b1)\n",
    "        if not(math.isnan(a1)):\n",
    "            std.append(b.iloc[d, 1].values.std()) # Append the std of the family of repeats\n",
    "            X_DF.loc[X_DF[\"ID\"] == b.iloc[d[0], 0], X_DF.columns[1]] = a1 # Put the average y to the \"first\"\n",
    "            d = []\n",
    "print(f\"Mean value of std for clones: {sum(std)/len(std):.2f} in {len(std)} rows\")\n",
    "#print(time.perf_counter() - t, 'sec. Alt 1 \\n')\n",
    "\n",
    "d = \"\"\" # ALTERNATIVA 2 ** AT LEAST TWICE LESS EFFICIENT - It changes b\n",
    "t = time.perf_counter()\n",
    "#b.reset_index(drop=True, inplace=True) # Otherwise index may be larger than b.shape[0]\n",
    "# Find the number of repeats, take \"y\" average and remove all clones but the \"first\"\n",
    "std = []\n",
    "for i in range(b.shape[0]):\n",
    "    if not(b.iloc[i, 2] == \"NONE\"):\n",
    "        mask = b[\"NEW\"] == b.iloc[i, 2]\n",
    "        d = b[mask].loc[:,\"y\"].values\n",
    "        X_DF.loc[X_DF[\"ID\"] == b.iloc[i, 0], X_DF.columns[1]] = d.mean() # Put the average y to the \"first\"\n",
    "        std.append(d.std()) # Append the std of the family of repeat\n",
    "        b.iloc[b[mask].index, 2] = \"NONE\"\n",
    "print(f\"Mean value of std for clones: {sum(std)/len(std):.2f} {len(std)}\")\n",
    "print(time.perf_counter() - t, 'sec. Alt 2')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3911, 364)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['k', 'v', 'at', ..., 0, 0, 0],\n",
       "       ['k', 't', 'av', ..., 0, 0, 0],\n",
       "       ['az', 'w', 'n', ..., 0, 0, 0],\n",
       "       ...,\n",
       "       ['ak', 'v', 'r', ..., 0, 0, 0],\n",
       "       ['al', 'r', 'e', ..., 0, 0, 0],\n",
       "       ['z', 'r', 'ae', ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From dataframe to arrays\n",
    "y_DF = X_DF['y'].values # From a pandas series to a numpy array\n",
    "# Make a new list with the labels of all Feature columns\n",
    "cols = [c for c in X_DF.columns if 'X' in c]\n",
    "# Using Shape to understand the shape of the data\n",
    "X_DF = X_DF[cols].values # From Frame to a numpy array\n",
    "print(X_DF.shape)\n",
    "X_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3911, 195) without 1-hot features\n",
      "(3911, 551) with 1-hot features\n",
      "(3911,) targets\n"
     ]
    }
   ],
   "source": [
    "# Item 3 from list above: APLYING LABEL ENCODER\n",
    "# To convert categorical features to features that can be used with estimators\n",
    "# we use a one-of-K, also known as one-hot or dummy encoding. This type of \n",
    "# encoding transforms each categorical feature with n_categories possible \n",
    "# values into n_categories binary features, with one of them 1, and all others 0.\n",
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_DF[:,0:8])\n",
    "#print(enc.categories_)# The categories for each feature\n",
    "#enc.transform([['k', 'v', 'at', 'a', 'd', 'u', 'j', 'o']]).toarray()\n",
    "X1=enc.transform(X_DF[:,0:8]).toarray()\n",
    "print(X1.shape,\"without 1-hot features\")\n",
    "X1 = np.append(X1[:,:], X_DF[:,8:], axis=1) # Sergio\n",
    "print(X1.shape,\"with 1-hot features\")\n",
    "print(y_DF.shape, \"targets\")\n",
    "#print(X1[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Forming the model\n",
    "The following steps will be taken.\n",
    "\n",
    "1. Split the samples in a train and a validation set.\n",
    "2. Reduce the dimensions with PSA\n",
    "3. Fit the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the original Feature -> Target we create a train and a validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "        X1, y_DF, test_size=0.15, \n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca explained variance ratio: 0.9995 (with 325 more significant components of 551)\n"
     ]
    }
   ],
   "source": [
    "# 4 item from list above: DIMENSDIONALITY REDUCTION WITH PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# The number of features, x_train.shape[1], is 551. 100 features explain 90.7% of variations\n",
    "# 225 features explain 99% of variations. 325 features 99.95 % of variations\n",
    "n_comp = 325\n",
    "# Try and error showed n_comp=100 is sound\n",
    "pca = PCA(n_components=n_comp, random_state=0)\n",
    "X_pca = pca.fit_transform(x_train)\n",
    "X_pcaV = pca.transform(x_valid)\n",
    "print(f\"pca explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\\\n",
    " (with {n_comp} more significant components of {x_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:97.05156\ttrain-r2:-57.04910\tvalid-rmse:96.01337\tvalid-r2:-65.04721\n",
      "[2]\ttrain-rmse:95.13505\ttrain-r2:-54.77910\tvalid-rmse:94.10549\tvalid-r2:-62.44848\n",
      "[3]\ttrain-rmse:93.25716\ttrain-r2:-52.59880\tvalid-rmse:92.23646\tvalid-r2:-59.95319\n",
      "[4]\ttrain-rmse:91.41776\ttrain-r2:-50.50522\tvalid-rmse:90.40443\tvalid-r2:-57.55590\n",
      "[5]\ttrain-rmse:89.61493\ttrain-r2:-48.49383\tvalid-rmse:88.60884\tvalid-r2:-55.25297\n",
      "[6]\ttrain-rmse:87.84840\ttrain-r2:-46.56179\tvalid-rmse:86.84888\tvalid-r2:-53.04054\n",
      "[7]\ttrain-rmse:86.11717\ttrain-r2:-44.70577\tvalid-rmse:85.12682\tvalid-r2:-50.91871\n",
      "[8]\ttrain-rmse:84.42181\ttrain-r2:-42.92379\tvalid-rmse:83.43864\tvalid-r2:-48.87994\n",
      "[9]\ttrain-rmse:82.76022\ttrain-r2:-41.21179\tvalid-rmse:81.78461\tvalid-r2:-46.92191\n",
      "[10]\ttrain-rmse:81.13265\ttrain-r2:-39.56778\tvalid-rmse:80.16218\tvalid-r2:-45.03948\n",
      "[11]\ttrain-rmse:79.53739\ttrain-r2:-37.98825\tvalid-rmse:78.57205\tvalid-r2:-43.23106\n",
      "[12]\ttrain-rmse:77.97478\ttrain-r2:-36.47131\tvalid-rmse:77.01699\tvalid-r2:-41.49759\n",
      "[13]\ttrain-rmse:76.44357\ttrain-r2:-35.01410\tvalid-rmse:75.49454\tvalid-r2:-39.83400\n",
      "[14]\ttrain-rmse:74.94321\ttrain-r2:-33.61424\tvalid-rmse:74.00206\tvalid-r2:-38.23548\n",
      "[15]\ttrain-rmse:73.47348\ttrain-r2:-32.26992\tvalid-rmse:72.53596\tvalid-r2:-36.69623\n",
      "[16]\ttrain-rmse:72.03315\ttrain-r2:-30.97828\tvalid-rmse:71.10014\tvalid-r2:-35.21865\n",
      "[17]\ttrain-rmse:70.62198\ttrain-r2:-29.73758\tvalid-rmse:69.69431\tvalid-r2:-33.80053\n",
      "[18]\ttrain-rmse:69.23943\ttrain-r2:-28.54592\tvalid-rmse:68.31792\tvalid-r2:-32.43957\n",
      "[19]\ttrain-rmse:67.88465\ttrain-r2:-27.40100\tvalid-rmse:66.96748\tvalid-r2:-31.13060\n",
      "[21]\ttrain-rmse:65.25709\ttrain-r2:-25.24495\tvalid-rmse:64.34540\tvalid-r2:-28.66376\n",
      "[22]\ttrain-rmse:63.98318\ttrain-r2:-24.23029\tvalid-rmse:63.07628\tvalid-r2:-27.50516\n",
      "[23]\ttrain-rmse:62.73512\ttrain-r2:-23.25560\tvalid-rmse:61.83509\tvalid-r2:-26.39437\n",
      "[24]\ttrain-rmse:61.51237\ttrain-r2:-22.31927\tvalid-rmse:60.62121\tvalid-r2:-25.32937\n",
      "[25]\ttrain-rmse:60.31421\ttrain-r2:-21.41970\tvalid-rmse:59.42150\tvalid-r2:-24.29755\n",
      "[26]\ttrain-rmse:59.14013\ttrain-r2:-20.55533\tvalid-rmse:58.25447\tvalid-r2:-23.31364\n",
      "[27]\ttrain-rmse:57.99021\ttrain-r2:-19.72526\tvalid-rmse:57.11087\tvalid-r2:-22.36841\n",
      "[28]\ttrain-rmse:56.86293\ttrain-r2:-18.92734\tvalid-rmse:55.98887\tvalid-r2:-21.45923\n",
      "[29]\ttrain-rmse:55.75928\ttrain-r2:-18.16130\tvalid-rmse:54.88700\tvalid-r2:-20.58391\n",
      "[30]\ttrain-rmse:54.67738\ttrain-r2:-17.42494\tvalid-rmse:53.81113\tvalid-r2:-19.74604\n",
      "[31]\ttrain-rmse:53.61849\ttrain-r2:-16.71819\tvalid-rmse:52.75438\tvalid-r2:-18.93922\n",
      "[32]\ttrain-rmse:52.58057\ttrain-r2:-16.03888\tvalid-rmse:51.71779\tvalid-r2:-18.16334\n",
      "[33]\ttrain-rmse:51.56345\ttrain-r2:-15.38604\tvalid-rmse:50.70513\tvalid-r2:-17.42025\n",
      "[34]\ttrain-rmse:50.56749\ttrain-r2:-14.75918\tvalid-rmse:49.71511\tvalid-r2:-16.70794\n",
      "[35]\ttrain-rmse:49.59165\ttrain-r2:-14.15678\tvalid-rmse:48.74717\tvalid-r2:-16.02512\n",
      "[36]\ttrain-rmse:48.63564\ttrain-r2:-13.57808\tvalid-rmse:47.79368\tvalid-r2:-15.36561\n",
      "[37]\ttrain-rmse:47.69937\ttrain-r2:-13.02216\tvalid-rmse:46.86151\tvalid-r2:-14.73344\n",
      "[38]\ttrain-rmse:46.78206\ttrain-r2:-12.48807\tvalid-rmse:45.94860\tvalid-r2:-14.12641\n",
      "[39]\ttrain-rmse:45.88249\ttrain-r2:-11.97432\tvalid-rmse:45.05414\tvalid-r2:-13.54322\n",
      "[41]\ttrain-rmse:44.13882\ttrain-r2:-11.00694\tvalid-rmse:43.32008\tvalid-r2:-12.44529\n",
      "[42]\ttrain-rmse:43.29360\ttrain-r2:-10.55148\tvalid-rmse:42.48494\tvalid-r2:-11.93187\n",
      "[43]\ttrain-rmse:42.46578\ttrain-r2:-10.11396\tvalid-rmse:41.66701\tvalid-r2:-11.43873\n",
      "[44]\ttrain-rmse:41.65458\ttrain-r2:-9.69340\tvalid-rmse:40.86277\tvalid-r2:-10.96319\n",
      "[45]\ttrain-rmse:40.86069\ttrain-r2:-9.28967\tvalid-rmse:40.07576\tvalid-r2:-10.50680\n",
      "[46]\ttrain-rmse:40.08284\ttrain-r2:-8.90163\tvalid-rmse:39.30765\tvalid-r2:-10.06994\n",
      "[47]\ttrain-rmse:39.32116\ttrain-r2:-8.52892\tvalid-rmse:38.55101\tvalid-r2:-9.64787\n",
      "[48]\ttrain-rmse:38.57433\ttrain-r2:-8.17038\tvalid-rmse:37.81198\tvalid-r2:-9.24354\n",
      "[49]\ttrain-rmse:37.84328\ttrain-r2:-7.82608\tvalid-rmse:37.08670\tvalid-r2:-8.85434\n",
      "[50]\ttrain-rmse:37.12750\ttrain-r2:-7.49537\tvalid-rmse:36.37704\tvalid-r2:-8.48083\n",
      "[51]\ttrain-rmse:36.42582\ttrain-r2:-7.17730\tvalid-rmse:35.68377\tvalid-r2:-8.12290\n",
      "[52]\ttrain-rmse:35.73835\ttrain-r2:-6.87154\tvalid-rmse:35.00708\tvalid-r2:-7.78017\n",
      "[53]\ttrain-rmse:35.06520\ttrain-r2:-6.57780\tvalid-rmse:34.34750\tvalid-r2:-7.45242\n",
      "[54]\ttrain-rmse:34.40594\ttrain-r2:-6.29554\tvalid-rmse:33.69844\tvalid-r2:-7.13600\n",
      "[55]\ttrain-rmse:33.76033\ttrain-r2:-6.02431\tvalid-rmse:33.06466\tvalid-r2:-6.83284\n",
      "[56]\ttrain-rmse:33.12733\ttrain-r2:-5.76337\tvalid-rmse:32.44146\tvalid-r2:-6.54036\n",
      "[57]\ttrain-rmse:32.50738\ttrain-r2:-5.51260\tvalid-rmse:31.83881\tvalid-r2:-6.26281\n",
      "[58]\ttrain-rmse:31.89937\ttrain-r2:-5.27126\tvalid-rmse:31.25152\tvalid-r2:-5.99735\n",
      "[59]\ttrain-rmse:31.30455\ttrain-r2:-5.03956\tvalid-rmse:30.66685\tvalid-r2:-5.73798\n",
      "[61]\ttrain-rmse:30.15002\ttrain-r2:-4.60229\tvalid-rmse:29.54118\tvalid-r2:-5.25240\n",
      "[62]\ttrain-rmse:29.59063\ttrain-r2:-4.39634\tvalid-rmse:28.99090\tvalid-r2:-5.02164\n",
      "[63]\ttrain-rmse:29.04250\ttrain-r2:-4.19827\tvalid-rmse:28.45588\tvalid-r2:-4.80144\n",
      "[64]\ttrain-rmse:28.50545\ttrain-r2:-4.00779\tvalid-rmse:27.92562\tvalid-r2:-4.58723\n",
      "[65]\ttrain-rmse:27.97827\ttrain-r2:-3.82427\tvalid-rmse:27.41601\tvalid-r2:-4.38518\n",
      "[66]\ttrain-rmse:27.46176\ttrain-r2:-3.64779\tvalid-rmse:26.92363\tvalid-r2:-4.19348\n",
      "[67]\ttrain-rmse:26.95576\ttrain-r2:-3.47810\tvalid-rmse:26.43792\tvalid-r2:-4.00779\n",
      "[68]\ttrain-rmse:26.45993\ttrain-r2:-3.31487\tvalid-rmse:25.96844\tvalid-r2:-3.83151\n",
      "[69]\ttrain-rmse:25.97396\ttrain-r2:-3.15784\tvalid-rmse:25.50559\tvalid-r2:-3.66082\n",
      "[70]\ttrain-rmse:25.49791\ttrain-r2:-3.00682\tvalid-rmse:25.03597\tvalid-r2:-3.49076\n",
      "[71]\ttrain-rmse:25.03118\ttrain-r2:-2.86147\tvalid-rmse:24.59218\tvalid-r2:-3.33297\n",
      "[72]\ttrain-rmse:24.57386\ttrain-r2:-2.72166\tvalid-rmse:24.16353\tvalid-r2:-3.18323\n",
      "[73]\ttrain-rmse:24.12528\ttrain-r2:-2.58703\tvalid-rmse:23.73261\tvalid-r2:-3.03536\n",
      "[74]\ttrain-rmse:23.68553\ttrain-r2:-2.45746\tvalid-rmse:23.30592\tvalid-r2:-2.89156\n",
      "[75]\ttrain-rmse:23.25467\ttrain-r2:-2.33281\tvalid-rmse:22.88607\tvalid-r2:-2.75262\n",
      "[76]\ttrain-rmse:22.83216\ttrain-r2:-2.21280\tvalid-rmse:22.48260\tvalid-r2:-2.62146\n",
      "[77]\ttrain-rmse:22.41762\ttrain-r2:-2.09720\tvalid-rmse:22.09401\tvalid-r2:-2.49736\n",
      "[78]\ttrain-rmse:22.01155\ttrain-r2:-1.98602\tvalid-rmse:21.70860\tvalid-r2:-2.37641\n",
      "[79]\ttrain-rmse:21.61365\ttrain-r2:-1.87903\tvalid-rmse:21.34323\tvalid-r2:-2.26371\n",
      "[81]\ttrain-rmse:20.84115\ttrain-r2:-1.67691\tvalid-rmse:20.63229\tvalid-r2:-2.04990\n",
      "[82]\ttrain-rmse:20.46638\ttrain-r2:-1.58150\tvalid-rmse:20.29050\tvalid-r2:-1.94969\n",
      "[83]\ttrain-rmse:20.09880\ttrain-r2:-1.48961\tvalid-rmse:19.95191\tvalid-r2:-1.85207\n",
      "[84]\ttrain-rmse:19.73806\ttrain-r2:-1.40104\tvalid-rmse:19.63090\tvalid-r2:-1.76103\n",
      "[85]\ttrain-rmse:19.38533\ttrain-r2:-1.31599\tvalid-rmse:19.31208\tvalid-r2:-1.67208\n",
      "[86]\ttrain-rmse:19.03893\ttrain-r2:-1.23396\tvalid-rmse:19.00123\tvalid-r2:-1.58675\n",
      "[87]\ttrain-rmse:18.69904\ttrain-r2:-1.15491\tvalid-rmse:18.69577\tvalid-r2:-1.50425\n",
      "[88]\ttrain-rmse:18.36445\ttrain-r2:-1.07848\tvalid-rmse:18.39313\tvalid-r2:-1.42383\n",
      "[89]\ttrain-rmse:18.03694\ttrain-r2:-1.00501\tvalid-rmse:18.10926\tvalid-r2:-1.34959\n",
      "[90]\ttrain-rmse:17.71539\ttrain-r2:-0.93416\tvalid-rmse:17.82190\tvalid-r2:-1.27562\n",
      "[91]\ttrain-rmse:17.40021\ttrain-r2:-0.86595\tvalid-rmse:17.54055\tvalid-r2:-1.20434\n",
      "[92]\ttrain-rmse:17.09113\ttrain-r2:-0.80025\tvalid-rmse:17.27164\tvalid-r2:-1.13727\n",
      "[93]\ttrain-rmse:16.78762\ttrain-r2:-0.73687\tvalid-rmse:17.00891\tvalid-r2:-1.07274\n",
      "[94]\ttrain-rmse:16.49022\ttrain-r2:-0.67588\tvalid-rmse:16.75144\tvalid-r2:-1.01046\n",
      "[95]\ttrain-rmse:16.19892\ttrain-r2:-0.61720\tvalid-rmse:16.49974\tvalid-r2:-0.95050\n",
      "[96]\ttrain-rmse:15.91234\ttrain-r2:-0.56048\tvalid-rmse:16.25515\tvalid-r2:-0.89310\n",
      "[97]\ttrain-rmse:15.63190\ttrain-r2:-0.50596\tvalid-rmse:16.02007\tvalid-r2:-0.83874\n",
      "[98]\ttrain-rmse:15.35701\ttrain-r2:-0.45346\tvalid-rmse:15.79226\tvalid-r2:-0.78682\n",
      "[99]\ttrain-rmse:15.08646\ttrain-r2:-0.40270\tvalid-rmse:15.56490\tvalid-r2:-0.73574\n",
      "[101]\ttrain-rmse:14.56199\ttrain-r2:-0.30687\tvalid-rmse:15.13218\tvalid-r2:-0.64057\n",
      "[102]\ttrain-rmse:14.30687\ttrain-r2:-0.26148\tvalid-rmse:14.92050\tvalid-r2:-0.59499\n",
      "[103]\ttrain-rmse:14.05661\ttrain-r2:-0.21773\tvalid-rmse:14.71825\tvalid-r2:-0.55204\n",
      "[104]\ttrain-rmse:13.81112\ttrain-r2:-0.17557\tvalid-rmse:14.52197\tvalid-r2:-0.51092\n",
      "[105]\ttrain-rmse:13.56994\ttrain-r2:-0.13487\tvalid-rmse:14.33013\tvalid-r2:-0.47127\n",
      "[106]\ttrain-rmse:13.33343\ttrain-r2:-0.09566\tvalid-rmse:14.13952\tvalid-r2:-0.43239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107]\ttrain-rmse:13.10119\ttrain-r2:-0.05782\tvalid-rmse:13.95571\tvalid-r2:-0.39539\n",
      "[108]\ttrain-rmse:12.87368\ttrain-r2:-0.02140\tvalid-rmse:13.77474\tvalid-r2:-0.35944\n",
      "[109]\ttrain-rmse:12.65047\ttrain-r2:0.01371\tvalid-rmse:13.60384\tvalid-r2:-0.32591\n",
      "[110]\ttrain-rmse:12.43156\ttrain-r2:0.04755\tvalid-rmse:13.43439\tvalid-r2:-0.29308\n",
      "[111]\ttrain-rmse:12.21624\ttrain-r2:0.08026\tvalid-rmse:13.27191\tvalid-r2:-0.26200\n",
      "[112]\ttrain-rmse:12.00547\ttrain-r2:0.11172\tvalid-rmse:13.11691\tvalid-r2:-0.23269\n",
      "[113]\ttrain-rmse:11.79861\ttrain-r2:0.14207\tvalid-rmse:12.96102\tvalid-r2:-0.20357\n",
      "[114]\ttrain-rmse:11.59553\ttrain-r2:0.17135\tvalid-rmse:12.81068\tvalid-r2:-0.17581\n",
      "[115]\ttrain-rmse:11.39664\ttrain-r2:0.19953\tvalid-rmse:12.66266\tvalid-r2:-0.14879\n",
      "[116]\ttrain-rmse:11.19892\ttrain-r2:0.22707\tvalid-rmse:12.52088\tvalid-r2:-0.12321\n",
      "[117]\ttrain-rmse:11.00680\ttrain-r2:0.25336\tvalid-rmse:12.37877\tvalid-r2:-0.09786\n",
      "[118]\ttrain-rmse:10.81656\ttrain-r2:0.27894\tvalid-rmse:12.24119\tvalid-r2:-0.07359\n",
      "[119]\ttrain-rmse:10.63047\ttrain-r2:0.30354\tvalid-rmse:12.10986\tvalid-r2:-0.05068\n",
      "[121]\ttrain-rmse:10.27032\ttrain-r2:0.34993\tvalid-rmse:11.85564\tvalid-r2:-0.00703\n",
      "[122]\ttrain-rmse:10.09448\ttrain-r2:0.37200\tvalid-rmse:11.73578\tvalid-r2:0.01323\n",
      "[123]\ttrain-rmse:9.92076\ttrain-r2:0.39343\tvalid-rmse:11.61985\tvalid-r2:0.03263\n",
      "[124]\ttrain-rmse:9.75117\ttrain-r2:0.41399\tvalid-rmse:11.50630\tvalid-r2:0.05144\n",
      "[125]\ttrain-rmse:9.58508\ttrain-r2:0.43378\tvalid-rmse:11.39641\tvalid-r2:0.06948\n",
      "[126]\ttrain-rmse:9.42079\ttrain-r2:0.45303\tvalid-rmse:11.28698\tvalid-r2:0.08726\n",
      "[127]\ttrain-rmse:9.26111\ttrain-r2:0.47141\tvalid-rmse:11.17787\tvalid-r2:0.10482\n",
      "[128]\ttrain-rmse:9.10335\ttrain-r2:0.48927\tvalid-rmse:11.07624\tvalid-r2:0.12103\n",
      "[129]\ttrain-rmse:8.94789\ttrain-r2:0.50656\tvalid-rmse:10.97588\tvalid-r2:0.13688\n",
      "[130]\ttrain-rmse:8.79570\ttrain-r2:0.52321\tvalid-rmse:10.87660\tvalid-r2:0.15243\n",
      "[131]\ttrain-rmse:8.64581\ttrain-r2:0.53932\tvalid-rmse:10.78391\tvalid-r2:0.16681\n",
      "[132]\ttrain-rmse:8.49925\ttrain-r2:0.55480\tvalid-rmse:10.69488\tvalid-r2:0.18051\n",
      "[133]\ttrain-rmse:8.35477\ttrain-r2:0.56981\tvalid-rmse:10.60665\tvalid-r2:0.19398\n",
      "[134]\ttrain-rmse:8.21368\ttrain-r2:0.58422\tvalid-rmse:10.51391\tvalid-r2:0.20801\n",
      "[135]\ttrain-rmse:8.07508\ttrain-r2:0.59813\tvalid-rmse:10.42997\tvalid-r2:0.22060\n",
      "[136]\ttrain-rmse:7.93837\ttrain-r2:0.61162\tvalid-rmse:10.34934\tvalid-r2:0.23261\n",
      "[137]\ttrain-rmse:7.80506\ttrain-r2:0.62456\tvalid-rmse:10.26502\tvalid-r2:0.24506\n",
      "[138]\ttrain-rmse:7.67414\ttrain-r2:0.63705\tvalid-rmse:10.19040\tvalid-r2:0.25600\n",
      "[139]\ttrain-rmse:7.54571\ttrain-r2:0.64909\tvalid-rmse:10.11066\tvalid-r2:0.26760\n",
      "[141]\ttrain-rmse:7.29339\ttrain-r2:0.67217\tvalid-rmse:9.96639\tvalid-r2:0.28835\n",
      "[142]\ttrain-rmse:7.17095\ttrain-r2:0.68308\tvalid-rmse:9.89631\tvalid-r2:0.29832\n",
      "[143]\ttrain-rmse:7.05107\ttrain-r2:0.69359\tvalid-rmse:9.82383\tvalid-r2:0.30856\n",
      "[144]\ttrain-rmse:6.93333\ttrain-r2:0.70374\tvalid-rmse:9.75513\tvalid-r2:0.31820\n",
      "[145]\ttrain-rmse:6.81779\ttrain-r2:0.71353\tvalid-rmse:9.69442\tvalid-r2:0.32666\n",
      "[146]\ttrain-rmse:6.70432\ttrain-r2:0.72299\tvalid-rmse:9.63787\tvalid-r2:0.33449\n",
      "[147]\ttrain-rmse:6.59309\ttrain-r2:0.73210\tvalid-rmse:9.58365\tvalid-r2:0.34196\n",
      "[148]\ttrain-rmse:6.48319\ttrain-r2:0.74096\tvalid-rmse:9.53368\tvalid-r2:0.34880\n",
      "[149]\ttrain-rmse:6.37514\ttrain-r2:0.74952\tvalid-rmse:9.48462\tvalid-r2:0.35549\n",
      "[150]\ttrain-rmse:6.26916\ttrain-r2:0.75778\tvalid-rmse:9.43743\tvalid-r2:0.36189\n",
      "[151]\ttrain-rmse:6.16507\ttrain-r2:0.76576\tvalid-rmse:9.39015\tvalid-r2:0.36826\n",
      "[152]\ttrain-rmse:6.06299\ttrain-r2:0.77345\tvalid-rmse:9.34376\tvalid-r2:0.37449\n",
      "[153]\ttrain-rmse:5.96307\ttrain-r2:0.78086\tvalid-rmse:9.29783\tvalid-r2:0.38062\n",
      "[154]\ttrain-rmse:5.86509\ttrain-r2:0.78800\tvalid-rmse:9.25377\tvalid-r2:0.38648\n",
      "[155]\ttrain-rmse:5.76829\ttrain-r2:0.79494\tvalid-rmse:9.21021\tvalid-r2:0.39224\n",
      "[156]\ttrain-rmse:5.67317\ttrain-r2:0.80165\tvalid-rmse:9.16776\tvalid-r2:0.39783\n",
      "[157]\ttrain-rmse:5.58013\ttrain-r2:0.80810\tvalid-rmse:9.12783\tvalid-r2:0.40307\n",
      "[158]\ttrain-rmse:5.48842\ttrain-r2:0.81435\tvalid-rmse:9.08989\tvalid-r2:0.40802\n",
      "[159]\ttrain-rmse:5.39837\ttrain-r2:0.82040\tvalid-rmse:9.05458\tvalid-r2:0.41261\n",
      "[161]\ttrain-rmse:5.22248\ttrain-r2:0.83191\tvalid-rmse:8.98185\tvalid-r2:0.42201\n",
      "[162]\ttrain-rmse:5.13697\ttrain-r2:0.83737\tvalid-rmse:8.94618\tvalid-r2:0.42659\n",
      "[163]\ttrain-rmse:5.05251\ttrain-r2:0.84267\tvalid-rmse:8.91411\tvalid-r2:0.43069\n",
      "[164]\ttrain-rmse:4.96946\ttrain-r2:0.84780\tvalid-rmse:8.88322\tvalid-r2:0.43463\n",
      "[165]\ttrain-rmse:4.88799\ttrain-r2:0.85275\tvalid-rmse:8.85471\tvalid-r2:0.43825\n",
      "[166]\ttrain-rmse:4.80794\ttrain-r2:0.85754\tvalid-rmse:8.82748\tvalid-r2:0.44170\n",
      "[167]\ttrain-rmse:4.72934\ttrain-r2:0.86215\tvalid-rmse:8.80120\tvalid-r2:0.44502\n",
      "[168]\ttrain-rmse:4.65226\ttrain-r2:0.86661\tvalid-rmse:8.77537\tvalid-r2:0.44828\n",
      "[169]\ttrain-rmse:4.57668\ttrain-r2:0.87091\tvalid-rmse:8.74974\tvalid-r2:0.45149\n",
      "[170]\ttrain-rmse:4.50213\ttrain-r2:0.87508\tvalid-rmse:8.72576\tvalid-r2:0.45450\n",
      "[171]\ttrain-rmse:4.42904\ttrain-r2:0.87911\tvalid-rmse:8.70437\tvalid-r2:0.45717\n",
      "[172]\ttrain-rmse:4.35763\ttrain-r2:0.88297\tvalid-rmse:8.68452\tvalid-r2:0.45964\n",
      "[173]\ttrain-rmse:4.28717\ttrain-r2:0.88673\tvalid-rmse:8.66249\tvalid-r2:0.46238\n",
      "[174]\ttrain-rmse:4.21763\ttrain-r2:0.89037\tvalid-rmse:8.64283\tvalid-r2:0.46482\n",
      "[175]\ttrain-rmse:4.15004\ttrain-r2:0.89386\tvalid-rmse:8.62437\tvalid-r2:0.46710\n",
      "[176]\ttrain-rmse:4.08308\ttrain-r2:0.89725\tvalid-rmse:8.60263\tvalid-r2:0.46978\n",
      "[177]\ttrain-rmse:4.01771\ttrain-r2:0.90052\tvalid-rmse:8.58404\tvalid-r2:0.47207\n",
      "[178]\ttrain-rmse:3.95299\ttrain-r2:0.90370\tvalid-rmse:8.56801\tvalid-r2:0.47404\n",
      "[179]\ttrain-rmse:3.88950\ttrain-r2:0.90677\tvalid-rmse:8.54843\tvalid-r2:0.47644\n",
      "[181]\ttrain-rmse:3.76585\ttrain-r2:0.91260\tvalid-rmse:8.51532\tvalid-r2:0.48049\n",
      "[182]\ttrain-rmse:3.70570\ttrain-r2:0.91537\tvalid-rmse:8.49632\tvalid-r2:0.48281\n",
      "[183]\ttrain-rmse:3.64669\ttrain-r2:0.91804\tvalid-rmse:8.47735\tvalid-r2:0.48511\n",
      "[184]\ttrain-rmse:3.58878\ttrain-r2:0.92063\tvalid-rmse:8.46062\tvalid-r2:0.48714\n",
      "[185]\ttrain-rmse:3.53200\ttrain-r2:0.92312\tvalid-rmse:8.44244\tvalid-r2:0.48934\n",
      "[186]\ttrain-rmse:3.47618\ttrain-r2:0.92553\tvalid-rmse:8.42615\tvalid-r2:0.49131\n",
      "[187]\ttrain-rmse:3.42138\ttrain-r2:0.92786\tvalid-rmse:8.41131\tvalid-r2:0.49310\n",
      "[188]\ttrain-rmse:3.36740\ttrain-r2:0.93012\tvalid-rmse:8.39517\tvalid-r2:0.49505\n",
      "[189]\ttrain-rmse:3.31367\ttrain-r2:0.93233\tvalid-rmse:8.38331\tvalid-r2:0.49647\n",
      "[190]\ttrain-rmse:3.26094\ttrain-r2:0.93446\tvalid-rmse:8.37243\tvalid-r2:0.49778\n",
      "[191]\ttrain-rmse:3.20929\ttrain-r2:0.93652\tvalid-rmse:8.36155\tvalid-r2:0.49908\n",
      "[192]\ttrain-rmse:3.15858\ttrain-r2:0.93851\tvalid-rmse:8.35254\tvalid-r2:0.50016\n",
      "[193]\ttrain-rmse:3.10840\ttrain-r2:0.94045\tvalid-rmse:8.34283\tvalid-r2:0.50133\n",
      "[194]\ttrain-rmse:3.05947\ttrain-r2:0.94231\tvalid-rmse:8.33443\tvalid-r2:0.50233\n",
      "[195]\ttrain-rmse:3.01133\ttrain-r2:0.94411\tvalid-rmse:8.32456\tvalid-r2:0.50351\n",
      "[196]\ttrain-rmse:2.96391\ttrain-r2:0.94586\tvalid-rmse:8.31615\tvalid-r2:0.50451\n",
      "[197]\ttrain-rmse:2.91743\ttrain-r2:0.94754\tvalid-rmse:8.30661\tvalid-r2:0.50565\n",
      "[198]\ttrain-rmse:2.87160\ttrain-r2:0.94918\tvalid-rmse:8.29823\tvalid-r2:0.50664\n",
      "[199]\ttrain-rmse:2.82674\ttrain-r2:0.95076\tvalid-rmse:8.28951\tvalid-r2:0.50768\n",
      "[201]\ttrain-rmse:2.73901\ttrain-r2:0.95376\tvalid-rmse:8.27440\tvalid-r2:0.50947\n",
      "[202]\ttrain-rmse:2.69651\ttrain-r2:0.95519\tvalid-rmse:8.26675\tvalid-r2:0.51038\n",
      "[203]\ttrain-rmse:2.65444\ttrain-r2:0.95657\tvalid-rmse:8.26074\tvalid-r2:0.51109\n",
      "[204]\ttrain-rmse:2.61295\ttrain-r2:0.95792\tvalid-rmse:8.25438\tvalid-r2:0.51184\n",
      "[205]\ttrain-rmse:2.57246\ttrain-r2:0.95922\tvalid-rmse:8.24782\tvalid-r2:0.51262\n",
      "[206]\ttrain-rmse:2.53264\ttrain-r2:0.96047\tvalid-rmse:8.24151\tvalid-r2:0.51336\n",
      "[207]\ttrain-rmse:2.49328\ttrain-r2:0.96169\tvalid-rmse:8.23406\tvalid-r2:0.51424\n",
      "[208]\ttrain-rmse:2.45466\ttrain-r2:0.96287\tvalid-rmse:8.22735\tvalid-r2:0.51503\n",
      "[209]\ttrain-rmse:2.41656\ttrain-r2:0.96401\tvalid-rmse:8.22253\tvalid-r2:0.51560\n",
      "[210]\ttrain-rmse:2.37961\ttrain-r2:0.96510\tvalid-rmse:8.21767\tvalid-r2:0.51618\n",
      "[211]\ttrain-rmse:2.34314\ttrain-r2:0.96616\tvalid-rmse:8.21333\tvalid-r2:0.51668\n",
      "[212]\ttrain-rmse:2.30741\ttrain-r2:0.96719\tvalid-rmse:8.20891\tvalid-r2:0.51721\n",
      "[213]\ttrain-rmse:2.27223\ttrain-r2:0.96818\tvalid-rmse:8.20572\tvalid-r2:0.51758\n",
      "[214]\ttrain-rmse:2.23755\ttrain-r2:0.96914\tvalid-rmse:8.20098\tvalid-r2:0.51814\n",
      "[215]\ttrain-rmse:2.20335\ttrain-r2:0.97008\tvalid-rmse:8.19663\tvalid-r2:0.51865\n",
      "[216]\ttrain-rmse:2.16973\ttrain-r2:0.97099\tvalid-rmse:8.19162\tvalid-r2:0.51924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217]\ttrain-rmse:2.13672\ttrain-r2:0.97186\tvalid-rmse:8.18862\tvalid-r2:0.51959\n",
      "[218]\ttrain-rmse:2.10408\ttrain-r2:0.97272\tvalid-rmse:8.18498\tvalid-r2:0.52002\n",
      "[219]\ttrain-rmse:2.07224\ttrain-r2:0.97354\tvalid-rmse:8.18082\tvalid-r2:0.52050\n",
      "[221]\ttrain-rmse:2.01001\ttrain-r2:0.97510\tvalid-rmse:8.17572\tvalid-r2:0.52110\n",
      "[222]\ttrain-rmse:1.97961\ttrain-r2:0.97585\tvalid-rmse:8.17219\tvalid-r2:0.52151\n",
      "[223]\ttrain-rmse:1.95001\ttrain-r2:0.97657\tvalid-rmse:8.16993\tvalid-r2:0.52178\n",
      "[224]\ttrain-rmse:1.92055\ttrain-r2:0.97727\tvalid-rmse:8.16575\tvalid-r2:0.52227\n",
      "[225]\ttrain-rmse:1.89142\ttrain-r2:0.97795\tvalid-rmse:8.16320\tvalid-r2:0.52257\n",
      "[226]\ttrain-rmse:1.86290\ttrain-r2:0.97861\tvalid-rmse:8.16093\tvalid-r2:0.52283\n",
      "[227]\ttrain-rmse:1.83491\ttrain-r2:0.97925\tvalid-rmse:8.15919\tvalid-r2:0.52304\n",
      "[228]\ttrain-rmse:1.80729\ttrain-r2:0.97987\tvalid-rmse:8.15700\tvalid-r2:0.52329\n",
      "[229]\ttrain-rmse:1.78044\ttrain-r2:0.98046\tvalid-rmse:8.15333\tvalid-r2:0.52372\n",
      "[230]\ttrain-rmse:1.75386\ttrain-r2:0.98104\tvalid-rmse:8.15047\tvalid-r2:0.52406\n",
      "[231]\ttrain-rmse:1.72756\ttrain-r2:0.98161\tvalid-rmse:8.14879\tvalid-r2:0.52425\n",
      "[232]\ttrain-rmse:1.70172\ttrain-r2:0.98215\tvalid-rmse:8.14721\tvalid-r2:0.52444\n",
      "[233]\ttrain-rmse:1.67636\ttrain-r2:0.98268\tvalid-rmse:8.14540\tvalid-r2:0.52465\n",
      "[234]\ttrain-rmse:1.65152\ttrain-r2:0.98319\tvalid-rmse:8.14349\tvalid-r2:0.52487\n",
      "[235]\ttrain-rmse:1.62697\ttrain-r2:0.98369\tvalid-rmse:8.14111\tvalid-r2:0.52515\n",
      "[236]\ttrain-rmse:1.60318\ttrain-r2:0.98416\tvalid-rmse:8.13918\tvalid-r2:0.52537\n",
      "[237]\ttrain-rmse:1.57954\ttrain-r2:0.98462\tvalid-rmse:8.13745\tvalid-r2:0.52557\n",
      "[238]\ttrain-rmse:1.55619\ttrain-r2:0.98508\tvalid-rmse:8.13568\tvalid-r2:0.52578\n",
      "[239]\ttrain-rmse:1.53349\ttrain-r2:0.98551\tvalid-rmse:8.13498\tvalid-r2:0.52586\n",
      "[241]\ttrain-rmse:1.48890\ttrain-r2:0.98634\tvalid-rmse:8.13281\tvalid-r2:0.52612\n",
      "[242]\ttrain-rmse:1.46728\ttrain-r2:0.98673\tvalid-rmse:8.13182\tvalid-r2:0.52623\n",
      "[243]\ttrain-rmse:1.44576\ttrain-r2:0.98712\tvalid-rmse:8.13049\tvalid-r2:0.52639\n",
      "[244]\ttrain-rmse:1.42466\ttrain-r2:0.98749\tvalid-rmse:8.12955\tvalid-r2:0.52650\n",
      "[245]\ttrain-rmse:1.40409\ttrain-r2:0.98785\tvalid-rmse:8.12778\tvalid-r2:0.52670\n",
      "[246]\ttrain-rmse:1.38368\ttrain-r2:0.98820\tvalid-rmse:8.12695\tvalid-r2:0.52680\n",
      "[247]\ttrain-rmse:1.36380\ttrain-r2:0.98854\tvalid-rmse:8.12548\tvalid-r2:0.52697\n",
      "[248]\ttrain-rmse:1.34424\ttrain-r2:0.98886\tvalid-rmse:8.12365\tvalid-r2:0.52718\n",
      "[249]\ttrain-rmse:1.32504\ttrain-r2:0.98918\tvalid-rmse:8.12280\tvalid-r2:0.52728\n",
      "[250]\ttrain-rmse:1.30598\ttrain-r2:0.98949\tvalid-rmse:8.12129\tvalid-r2:0.52746\n",
      "[251]\ttrain-rmse:1.28720\ttrain-r2:0.98979\tvalid-rmse:8.12013\tvalid-r2:0.52759\n",
      "[252]\ttrain-rmse:1.26884\ttrain-r2:0.99008\tvalid-rmse:8.11974\tvalid-r2:0.52764\n",
      "[253]\ttrain-rmse:1.25084\ttrain-r2:0.99036\tvalid-rmse:8.11836\tvalid-r2:0.52780\n",
      "[254]\ttrain-rmse:1.23316\ttrain-r2:0.99063\tvalid-rmse:8.11671\tvalid-r2:0.52799\n",
      "[255]\ttrain-rmse:1.21573\ttrain-r2:0.99089\tvalid-rmse:8.11596\tvalid-r2:0.52808\n",
      "[256]\ttrain-rmse:1.19850\ttrain-r2:0.99115\tvalid-rmse:8.11476\tvalid-r2:0.52822\n",
      "[257]\ttrain-rmse:1.18154\ttrain-r2:0.99140\tvalid-rmse:8.11295\tvalid-r2:0.52843\n",
      "[258]\ttrain-rmse:1.16485\ttrain-r2:0.99164\tvalid-rmse:8.11185\tvalid-r2:0.52856\n",
      "[259]\ttrain-rmse:1.14846\ttrain-r2:0.99187\tvalid-rmse:8.11101\tvalid-r2:0.52865\n",
      "[261]\ttrain-rmse:1.11647\ttrain-r2:0.99232\tvalid-rmse:8.10930\tvalid-r2:0.52885\n",
      "[262]\ttrain-rmse:1.10080\ttrain-r2:0.99253\tvalid-rmse:8.10877\tvalid-r2:0.52891\n",
      "[263]\ttrain-rmse:1.08542\ttrain-r2:0.99274\tvalid-rmse:8.10812\tvalid-r2:0.52899\n",
      "[264]\ttrain-rmse:1.07022\ttrain-r2:0.99294\tvalid-rmse:8.10756\tvalid-r2:0.52905\n",
      "[265]\ttrain-rmse:1.05526\ttrain-r2:0.99314\tvalid-rmse:8.10707\tvalid-r2:0.52911\n",
      "[266]\ttrain-rmse:1.04056\ttrain-r2:0.99333\tvalid-rmse:8.10646\tvalid-r2:0.52918\n",
      "[267]\ttrain-rmse:1.02610\ttrain-r2:0.99351\tvalid-rmse:8.10580\tvalid-r2:0.52926\n",
      "[268]\ttrain-rmse:1.01190\ttrain-r2:0.99369\tvalid-rmse:8.10525\tvalid-r2:0.52932\n",
      "[269]\ttrain-rmse:0.99795\ttrain-r2:0.99386\tvalid-rmse:8.10458\tvalid-r2:0.52940\n",
      "[270]\ttrain-rmse:0.98414\ttrain-r2:0.99403\tvalid-rmse:8.10417\tvalid-r2:0.52945\n",
      "[271]\ttrain-rmse:0.97060\ttrain-r2:0.99419\tvalid-rmse:8.10364\tvalid-r2:0.52951\n",
      "[272]\ttrain-rmse:0.95723\ttrain-r2:0.99435\tvalid-rmse:8.10299\tvalid-r2:0.52958\n",
      "[273]\ttrain-rmse:0.94410\ttrain-r2:0.99451\tvalid-rmse:8.10263\tvalid-r2:0.52963\n",
      "[274]\ttrain-rmse:0.93117\ttrain-r2:0.99466\tvalid-rmse:8.10201\tvalid-r2:0.52970\n",
      "[275]\ttrain-rmse:0.91844\ttrain-r2:0.99480\tvalid-rmse:8.10122\tvalid-r2:0.52979\n",
      "[276]\ttrain-rmse:0.90588\ttrain-r2:0.99494\tvalid-rmse:8.10031\tvalid-r2:0.52990\n",
      "[277]\ttrain-rmse:0.89352\ttrain-r2:0.99508\tvalid-rmse:8.09975\tvalid-r2:0.52996\n",
      "[278]\ttrain-rmse:0.88135\ttrain-r2:0.99521\tvalid-rmse:8.09903\tvalid-r2:0.53004\n",
      "[279]\ttrain-rmse:0.86932\ttrain-r2:0.99534\tvalid-rmse:8.09882\tvalid-r2:0.53007\n"
     ]
    }
   ],
   "source": [
    "# More than 280 trials will cause overfitting. 280 trials minimize the validation set rms,\n",
    "# 8.01182, (just a little more than the rms for the repeated items, 5.55792, shown at In[6]).\n",
    "# If we do not remove the samples with identical features from the train set the rms of the\n",
    "# validation set becomes 11.14574. Below the complete statistics for both cases.\n",
    "# [279]\ttrain-rmse:0.91933\tvalid-rmse:8.01166\ttrain-r2:0.99479\tvalid-r2:0.54013\n",
    "# [279]\ttrain-rmse:2.18185\tvalid-rmse:11.14574\ttrain-r2:0.96927\tvalid-r2:0.35478\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "dt_x = xgb.DMatrix(X_pca, label=y_train)\n",
    "dt_v = xgb.DMatrix(X_pcaV, label=y_valid)\n",
    "params = {'objective': 'reg:squarederror', 'max_depth': 100,  'eta': 0.02}\n",
    "def R2_score(yp, db):\n",
    "    y = db.get_label()\n",
    "    return 'r2', r2_score(y, yp) \n",
    "watchlist = [(dt_x, 'train'), (dt_v, 'valid')]\n",
    "regr = xgb.train(params, dt_x, 280, watchlist, feval=R2_score, verbose_eval = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D) PREDICTING NEW TEST VALUES\n",
    "Since we have the model the task now is to comply with task number 5 \"Predict your test_df values using XGBoost\". First we read the test.csv and clean it sinse there are feature values not available in the trained set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 (4185, 377)\n"
     ]
    }
   ],
   "source": [
    "# Clean samples in test.csv having no same feature value as in train.csv\n",
    "# We got the \"elim\" and columns[X] by try and error method\n",
    "elim = ['bb', 'an', 'ag', 'av', 'ae', 'p']\n",
    "DFTEST = DFTEST.loc[~DFTEST[DFTEST.columns[1]].isin(elim)] #,  inplace=True)\n",
    "#print(1, DFTEST.shape)\n",
    "elim = ['u', 'ax', 'ab', 'ad', 'w', 'aj']\n",
    "DFTEST = DFTEST.loc[~DFTEST[DFTEST.columns[3]].isin(elim)] #,  inplace=True)\n",
    "#print(3, DFTEST.shape)\n",
    "elim = ['t', 'a', 'z', 'b']\n",
    "DFTEST = DFTEST.loc[~DFTEST[DFTEST.columns[6]].isin(elim)] #,  inplace=True)\n",
    "print(6, DFTEST.shape)\n",
    "# Now we make a copy in order to remove the same columns we removed from the trained set\n",
    "X_t = DFTEST.copy()\n",
    "for c in colsRmv:\n",
    "    X_t.drop(c, axis=\"columns\", inplace=True)\n",
    "X_t.drop(\"ID\", axis=\"columns\", inplace=True)\n",
    "X_t = X_t.values # LIST of arrays\n",
    "#print(X_t.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>110.078117</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>91.983849</td>\n",
       "      <td>y</td>\n",
       "      <td>aa</td>\n",
       "      <td>ai</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>g</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>112.357079</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>ae</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>95.787804</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>ae</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>118.142006</td>\n",
       "      <td>ap</td>\n",
       "      <td>l</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>j</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           y  X0  X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  \\\n",
       "4   5  110.078117   w   s  as  c  d  y  i  m  ...     1     0     0     0   \n",
       "5   8   91.983849   y  aa  ai  e  d  x  g  s  ...     1     0     0     0   \n",
       "6  10  112.357079   x   b  ae  d  d  x  d  y  ...     0     0     0     0   \n",
       "7  11   95.787804   f   s  ae  c  d  h  d  a  ...     0     0     1     0   \n",
       "8  12  118.142006  ap   l   s  c  d  h  j  n  ...     0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "4     0     0     0     0     0     0  \n",
       "5     0     0     0     0     0     0  \n",
       "6     0     1     0     0     0     0  \n",
       "7     0     0     0     0     0     0  \n",
       "8     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the copy with less columns to prepare the data to be fed to XGBoost\n",
    "X2 = [X_t[i,0:8] for i in range(X_t.shape[0])]\n",
    "# Transform X2 to a one-hot array\n",
    "X2=enc.transform(X2).toarray()\n",
    "#print(X2.shape)\n",
    "X2 = np.append(X2[:,:], X_t[:,8:], axis=1)\n",
    "# Reduce the features with the same pca structure used for the trained set\n",
    "X2 = pca.transform(X2)\n",
    "X2 = xgb.DMatrix(X2) # XGBoost demands a dataframe as input\n",
    "y = regr.predict(X2)\n",
    "# The last step is to insert the modeled target values to the test dataframe\n",
    "DFTEST.insert(1, \"y\", y)\n",
    "DFTEST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this part if you want to re run the Predicting new values part\n",
    "try:\n",
    "    del DFTEST[\"y\"] # or DFTEST.drop(\"y\", inplace = True, axis=1)\n",
    "except KeyError:\n",
    "    pass\n",
    "#DFTEST.head()\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "#                       T H E       E N D                                     #\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
